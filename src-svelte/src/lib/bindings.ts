/* eslint-disable */
// This file was generated by [tauri-specta](https://github.com/oscartbeaumont/tauri-specta). Do not edit this file manually.

declare global {
    interface Window {
        __TAURI_INVOKE__<T>(cmd: string, args?: Record<string, unknown>): Promise<T>;
    }
}

// Function avoids 'window not defined' in SSR
const invoke = () => window.__TAURI_INVOKE__;

export function getApiKeys() {
    return invoke()<ApiKeys>("get_api_keys")
}

export function setApiKey(filename: string | null, service: Service, apiKey: string) {
    return invoke()<null>("set_api_key", { filename,service,apiKey })
}

export function playSound(sound: Sound, volume: number, speed: number) {
    return invoke()<null>("play_sound", { sound,volume,speed })
}

export function getPreferences() {
    return invoke()<Preferences>("get_preferences")
}

export function setPreferences(preferences: Preferences) {
    return invoke()<null>("set_preferences", { preferences })
}

export function getSystemInfo() {
    return invoke()<SystemInfo>("get_system_info")
}

export function chat(provider: Service, llm: string, temperature: number | null, prompt: ChatMessage[]) {
    return invoke()<LlmCall>("chat", { provider,llm,temperature,prompt })
}

export type ApiKeys = { openai: string | null }
export type SystemInfo = { zamm_version: string; os: OS | null; shell: Shell | null; shell_init_file: string | null }
export type Request = { prompt: Prompt; temperature: number }
export type ChatMessage = { role: "System"; text: string } | { role: "Human"; text: string } | { role: "AI"; text: string }
export type Llm = { name: string; requested: string; provider: Service }
export type Response = { completion: ChatMessage }
export type Preferences = { animations_on: boolean | null; background_animation: boolean | null; animation_speed: number | null; sound_on: boolean | null; volume: number | null }
export type Service = "OpenAI"
export type EntityId = { id: string }
export type OS = "Mac" | "Linux" | "Windows"
export type Shell = "Bash" | "Zsh"
export type LlmCall = ({ id: string }) & { timestamp: string; llm: Llm; request: Request; response: Response; tokens: TokenMetadata }
export type TokenMetadata = { prompt: number | null; response: number | null; total: number | null }
export type Sound = "Switch" | "Whoosh"
export type Prompt = ({ type: "Chat" } & ChatPrompt)
export type ChatPrompt = { messages: ChatMessage[] }
